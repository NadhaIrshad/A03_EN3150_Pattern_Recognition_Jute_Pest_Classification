{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13393035,"sourceType":"datasetVersion","datasetId":8498646}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/induwarailukkumbura/fine-tuning-model?scriptVersionId=271625523\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T16:59:08.666306Z","iopub.execute_input":"2025-10-24T16:59:08.666584Z","iopub.status.idle":"2025-10-24T16:59:19.194677Z","shell.execute_reply.started":"2025-10-24T16:59:08.666557Z","shell.execute_reply":"2025-10-24T16:59:19.194054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = \"/kaggle/input/jute-pests/Dataset/Jute_Pest_Dataset\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:29:25.676546Z","iopub.execute_input":"2025-10-28T19:29:25.676781Z","iopub.status.idle":"2025-10-28T19:29:25.684675Z","shell.execute_reply.started":"2025-10-28T19:29:25.676753Z","shell.execute_reply":"2025-10-28T19:29:25.683797Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\n}\n\nimage_datasets = {\n    x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n    for x in ['train', 'val', 'test']\n}\n\ndataloaders = {\n    x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2)\n    for x in ['train', 'val', 'test']\n}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\nclass_names = image_datasets['train'].classes\nnum_classes = len(class_names)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Classes:\", class_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T17:09:13.905847Z","iopub.execute_input":"2025-10-24T17:09:13.906536Z","iopub.status.idle":"2025-10-24T17:09:21.262012Z","shell.execute_reply.started":"2025-10-24T17:09:13.906509Z","shell.execute_reply":"2025-10-24T17:09:21.261296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    train_loss, val_loss = [], []\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print(\"-\" * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            if phase == 'train':\n                train_loss.append(epoch_loss)\n                scheduler.step()\n            else:\n                val_loss.append(epoch_loss)\n\n            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n    time_elapsed = time.time() - since\n    print(f\"\\nTraining complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\")\n    print(f\"Best val Acc: {best_acc:.4f}\\n\")\n\n    model.load_state_dict(best_model_wts)\n    return model, train_loss, val_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T17:09:37.100534Z","iopub.execute_input":"2025-10-24T17:09:37.100825Z","iopub.status.idle":"2025-10-24T17:09:37.10911Z","shell.execute_reply.started":"2025-10-24T17:09:37.100804Z","shell.execute_reply":"2025-10-24T17:09:37.108411Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resnet = models.resnet50(pretrained=True)\n\n# Freeze earlier layers\nfor param in resnet.parameters():\n    param.requires_grad = False\n\n# Replace the classifier head\nnum_ftrs = resnet.fc.in_features\nresnet.fc = nn.Linear(num_ftrs, num_classes)\n\nresnet = resnet.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(resnet.fc.parameters(), lr=1e-3)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\nresnet_model, resnet_train_loss, resnet_val_loss = train_model(\n    resnet, criterion, optimizer, scheduler, num_epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T17:10:02.684747Z","iopub.execute_input":"2025-10-24T17:10:02.685285Z","iopub.status.idle":"2025-10-24T17:14:31.697103Z","shell.execute_reply.started":"2025-10-24T17:10:02.685253Z","shell.execute_reply":"2025-10-24T17:14:31.695972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"densenet = models.densenet121(pretrained=True)\n\n# Freeze feature extractor\nfor param in densenet.features.parameters():\n    param.requires_grad = False\n\nnum_ftrs = densenet.classifier.in_features\ndensenet.classifier = nn.Linear(num_ftrs, num_classes)\n\ndensenet = densenet.to(device)\noptimizer = optim.Adam(densenet.classifier.parameters(), lr=1e-3)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\ndensenet_model, dense_train_loss, dense_val_loss = train_model(\n    densenet, criterion, optimizer, scheduler, num_epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T17:18:14.236371Z","iopub.execute_input":"2025-10-24T17:18:14.237285Z","iopub.status.idle":"2025-10-24T17:22:47.527787Z","shell.execute_reply.started":"2025-10-24T17:18:14.237227Z","shell.execute_reply":"2025-10-24T17:22:47.526999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(resnet_train_loss, label='ResNet50 Train Loss')\nplt.plot(resnet_val_loss, label='ResNet50 Val Loss')\nplt.plot(dense_train_loss, label='DenseNet Train Loss')\nplt.plot(dense_val_loss, label='DenseNet Val Loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss Curves\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T17:23:14.847823Z","iopub.execute_input":"2025-10-24T17:23:14.848347Z","iopub.status.idle":"2025-10-24T17:23:15.043764Z","shell.execute_reply.started":"2025-10-24T17:23:14.848321Z","shell.execute_reply":"2025-10-24T17:23:15.043011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model):\n    model.eval()\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for inputs, labels in dataloaders['test']:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, all_preds))\n    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=class_names))\n\nprint(\"ðŸ“Š ResNet50 Results:\")\nevaluate_model(resnet_model)\n\nprint(\"\\nðŸ“Š DenseNet121 Results:\")\nevaluate_model(densenet_model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T17:23:36.126944Z","iopub.execute_input":"2025-10-24T17:23:36.12727Z","iopub.status.idle":"2025-10-24T17:23:39.957533Z","shell.execute_reply.started":"2025-10-24T17:23:36.12722Z","shell.execute_reply":"2025-10-24T17:23:39.956496Z"}},"outputs":[],"execution_count":null}]}